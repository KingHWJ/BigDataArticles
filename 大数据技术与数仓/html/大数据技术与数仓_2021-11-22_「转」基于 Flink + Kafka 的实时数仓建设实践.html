<html>
<head>
<title></title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0,viewport-fit=cover">
<style>
*{margin:0;padding:0}html{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;line-height:1.6}img{z-index:999;position:relative;max-width:100%;margin:10px 0;}body{letter-spacing:.034em}h1,h2,h3,h4,h5,h6{font-weight:400;font-size:16px}a{color:#576b95;text-decoration:none;-webkit-tap-highlight-color:rgba(0,0,0,0)}td,th{word-wrap:break-word;padding:5px 10px;border:1px solid #DDD;}table{margin-bottom:10px;border-collapse:collapse;display:table;width:100%!important;}.appmsg_skin_default .rich_media_area_primary{background-color:#fff}.appmsg_skin_default .rich_media_area_primary .weui-loadmore_line .weui-loadmore__tips{background-color:#fff}.rich_media_area_primary{padding:20px 16px 12px;background-color:#fafafa}@media (max-width:375px){.rich_media_area_primary{padding:20px 60px 15px 60px}.rich_media_area_extra{padding:0 60px 21px 60px}}@media (min-width:1024px){.rich_media_area_primary_inner,.rich_media_area_extra_inner,body{max-width:677px;margin-left:auto;margin-right:auto}.rich_media_area_primary{padding-top:32px}}.rich_media{padding:20px;overflow:hidden;}.appmsg_skin_default .rich_media_area_primary{background-color:#fff}.appmsg_skin_default .rich_media_area_primary .weui-loadmore_line .weui-loadmore__tips{background-color:#fff}@media screen and (min-width:1024px){.rich_media_area_primary_inner,.rich_media_area_extra_inner{max-width:677px;margin-left:auto;margin-right:auto}.rich_media_area_primary{padding-top:32px}}.rich_media_content{overflow:hidden;color:#333;font-size:17px;word-wrap:break-word;-webkit-hyphens:auto;-ms-hyphens:auto;hyphens:auto;text-align:justify;position:relative;z-index:0}.rich_media_content *{max-width:100%!important;box-sizing:border-box!important;-webkit-box-sizing:border-box!important;word-wrap:break-word!important}.rich_media_content p{clear:both;min-height:1em}.rich_media_content em{font-style:italic}.rich_media_content fieldset{min-width:0}.rich_media_content .list-paddingleft-1,.rich_media_content .list-paddingleft-2,.rich_media_content .list-paddingleft-3{padding-left:2.2em}.rich_media_content .list-paddingleft-1 .list-paddingleft-2,.rich_media_content .list-paddingleft-2 .list-paddingleft-2,.rich_media_content .list-paddingleft-3 .list-paddingleft-2{padding-left:30px}.rich_media_content .list-paddingleft-1{padding-left:1.2em}.rich_media_content .list-paddingleft-3{padding-left:3.2em}.rich_media_content .code-snippet,.rich_media_content .code-snippet__fix{max-width:1000%!important}.rich_media_content .code-snippet *,.rich_media_content .code-snippet__fix *{max-width:1000%!important}.rich_media_title{font-size:22px;line-height:1.4;margin-bottom:13px;padding-bottom:13px;border-bottom:1px solid #e7e7eb;}@supports(-webkit-overflow-scrolling:touch){.rich_media_title{font-weight:700}}.rich_media_meta{display:inline-block;vertical-align:middle;padding:0 0 10px 0;font-size:15px;-webkit-tap-highlight-color:rgba(0,0,0,0)}.rich_media_meta.icon_appmsg_tag{margin-right:0px}.rich_media_meta.meta_tag_text{margin-right:0}.rich_media_meta_list em{font-style:normal}.rich_media_meta_text{color:#a5a5a5;}p{margin:0;}.msgBox{margin-top:20px;padding-top:20px;padding-left:50px;overflow:hidden;border-top:2px dashed #09a2ff;}.msg{padding-top:7px;clear:both;}.msgBody{float:right;width:100%;margin-left:55px;padding-bottom:15px;border-bottom:1px dashed #e0e0e0;}.userHeadImg{float:left;margin-left:-50px;}.userHeadImg img{width:40px;height:40px;margin-right:10px;border-radius:3px;}.userName{color:#888888;line-height:24px;font-size:14px;margin:5px 0 5px 0;height:24px;}.replyBody,.autherBody{color:#565656;font-size:15px;}.replyIcon{border-left:4px solid #33ab01;margin-right:5px;}.ad{text-decoration:none;color:#d6d4d4;font-size:12px;}.msgBodyReply{padding-top:5px;}.userName span{float:right;color:#afafaf;font-size:14px;}code{text-align:left;font-size:14px;display:block;white-space:pre;display:-webkit-box;display:-webkit-flex;display:flex;position:relative;}.code-snippet__fix{font-size:14px;margin:10px 0;display:block;color:#333;position:relative;background-color:rgba(0,0,0,0.03);border:1px solid #f0f0f0;border-radius:2px;display:-webkit-box;display:-webkit-flex;display:flex;padding-left:25px;line-height:26px}.code-snippet__fix code{text-align:left;font-size:14px;display:block;white-space:pre;display:-webkit-box;display:-webkit-flex;display:flex;position:relative;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace}.code-snippet__comment,.code-snippet__quote{color:#afafaf;font-style:italic}.code-snippet__keyword,.code-snippet__selector-tag,.code-snippet__subst{color:#ca7d37}.code-snippet__number,.code-snippet__literal,.code-snippet__variable,.code-snippet__template-variable,.code-snippet__tag .code-snippet__attr{color:#0e9ce5}.code-snippet__string,.code-snippet__doctag{color:#d14}.code-snippet__title,.code-snippet__section,.code-snippet__selector-id{color:#d14}.code-snippet__subst{font-weight:normal}.code-snippet__type,.code-snippet__class .code-snippet__title{color:#0e9ce5}.code-snippet__tag,.code-snippet__name,.code-snippet__attribute{color:#0e9ce5;font-weight:normal}.code-snippet__regexp,.code-snippet__link{color:#ca7d37}.code-snippet__symbol,.code-snippet__bullet{color:#d14}.code-snippet__built_in,.code-snippet__builtin-name{color:#ca7d37}.code-snippet__meta{color:#afafaf}.code-snippet__deletion{background:#fdd}.code-snippet__addition{background:#dfd}.code-snippet__emphasis{font-style:italic}.code-snippet__strong{font-weight:bold}.account_avatar{width:40px;height:40px;padding:0;}.account_info{display:-webkit-box;display:-webkit-flex;display:flex;-webkit-box-align:center;-webkit-align-items:center;padding:20px 0;align-items:center}.flex_bd{padding-left:14px;}.account_nickname{display:inline-block;vertical-align:middle;line-height:1.2;color:#576b95;font-size:14px}.account_desc{overflow:hidden;text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:1;color:rgba(0,0,0,0.3);font-size:14px;line-height:1.2;padding-top:.4em}.msg_source_url{text-align:left;word-break:break-all;margin-top:20px;}.msg_source_url a{padding-right:10px;}.msg_source_url .url_text{color:#a8a8a8;}.video-desc{font-size:14px;margin-top:15px;color:#6c6c6c;}.msg_source_url{text-align:left;}.original_primary_card_tips{color:rgba(0,0,0,0.3);line-height:1.4;font-size:15px;}.weui-flex__item{margin-bottom:20px;padding:20px 16px;margin-top:16px;line-height:1.4;align-items:center;background-color:#f7f7f7;border-radius:8px;position:relative;}.original_primary_desc{color:rgba(0,0,0,0.5);font-size:14px;padding-top:4px;width:auto;overflow:hidden;text-overflow:ellipsis;}.msgBodyReplyList{border-top:1px solid #e1e1e1;margin-top:10px;}.msgBodyReplyListTop{border-top:0;}.reply_like_num{float:right;font-size:14px;color:#c7c7c7;}.msgData{margin-top:20px;color:#626262;}.msgData span{font-size:14px;padding-right:15px;}.msgData .likes{float:right;padding-right:0;}.js_text_content p{font-size:18px;}.rich_media_meta_link{font-size:15px;}blockquote {padding-left: 10px;border-left: 3px solid #dbdbdb;color: rgba(0,0,0,0.5);font-size: 15px;padding-top: 4px;margin: 1em 0;}.video_iframe{width:500px;height:400px;}.blockquote_info{color:#b5b5b5;margin-top:10px;}#copyright_logo{color:#bdbdbd;}.rich_media_meta_list{margin-bottom:10px;}.reprint{background:#efefef;border-radius:5px;padding:8px;color:#1f1f1f;}.reprint a{word-break:break-all;}.topic{color:#8e8e8e;background:#f7f7f7;border-radius:5px;padding:10px 8px;}.topic a{padding-right:5px;}.topic p{margin-bottom:5px;}
</style>
<link href="https://www.juyifx.cn/config/css/wxArticle.css" rel="stylesheet"/>
</head><script>
var data={"mp":"大数据技术与数仓","title":"基于 Flink + Kafka 的实时数仓建设实践","time":"2021-11-22 08:33:09","timeStamp":"1637541189"};
</script>
<body>
<div class="rich_media"><h1 class="rich_media_title" id="activity-name"><a href="http://mp.weixin.qq.com/s?__biz=MzU2ODQ3NjYyMA==&mid=2247487698&idx=2&sn=32da423ca22cfd6058172394b59c3aaa&chksm=fc8c0671cbfb8f67b4f2223b503c110a16c1cdb0b41d585cb692ac2feea614b217aee2b6b2d3#rd" target="_blank">基于 Flink + Kafka 的实时数仓建设实践</a></h1><div id="meta_content" class="rich_media_meta_list"><span class="rich_media_meta rich_media_meta_text">岳猛@网易云音乐&nbsp;&nbsp;</span><span class="rich_media_meta rich_media_meta_nickname" id="profileBt"><a href="javascript:void(0);" class="wx_tap_link js_wx_tap_highlight weui-wa-hotarea" id="js_name">大数据技术与数仓&nbsp;&nbsp;</a></span><em id="publish_time" class="rich_media_meta rich_media_meta_text">2021-11-22 08:33:09</em></div><content><div class="reprint"><p>转自公众号：Apache Flink<br><a href="http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&mid=2247489625&idx=1&sn=d30bdf8b8ce9ca5c062b02dcb6c735a9" target="_blank" title="阅读原文">http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&mid=2247489625&idx=1&sn=d30bdf8b8ce9ca5c062b02dcb6c735a9</a></p></div><section powered-by="xiumi.us" data-mpa-powered-by="yiban.io"><section><section label="Copyright Reserved by PLAYHUDONG." donone="shifuMouseDownCard(&#39;shifu_c_008&#39;)"><section class="mp_profile_iframe_wrp"><mpprofile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzU2ODQ3NjYyMA==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/PL10rfzHicsiaWUJ7uBrlIibLdUDlmsXrhE9b6ZXmFWGZFqzSQE7LFkL1XmLkmgAWibVYG7tpGyEjls5B0LWc8lkjg/0?wx_fmt=png" data-nickname="大数据技术与数仓" data-alias="bigdata_dw" data-signature="专注分享数据仓库与大数据技术(Flink/Hadoop/Spark/Hive)相关内容。关注我可以免费领取大数据书籍与视频。我的博客:https://jiamaoxiang.top/" data-from="0"></mpprofile></section><section style="max-width: 100%;font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);line-height: 1.75em;text-align: left;box-sizing: border-box !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(89, 89, 89);font-size: 15px;letter-spacing: 0.5px;box-sizing: border-box !important;overflow-wrap: break-word !important;">简介：</span><span style="max-width: 100%;color: rgb(89, 89, 89);font-size: 15px;letter-spacing: 0.5px;box-sizing: border-box !important;overflow-wrap: break-word !important;">本文由</span><span style="max-width: 100%;color: rgb(89, 89, 89);font-size: 15px;letter-spacing: 0.5px;box-sizing: border-box !important;overflow-wrap: break-word !important;">网易云音乐实时计算平台研发工程师岳猛</span><span style="max-width: 100%;color: rgb(89, 89, 89);font-size: 15px;letter-spacing: 0.5px;box-sizing: border-box !important;overflow-wrap: break-word !important;">分享，主要从以下四个部分</span><span style="max-width: 100%;color: rgb(89, 89, 89);font-size: 15px;letter-spacing: 0.5px;box-sizing: border-box !important;overflow-wrap: break-word !important;">将为大家介绍 Flink + Kaf</span><span style="max-width: 100%;color: rgb(89, 89, 89);font-size: 15px;letter-spacing: 0.5px;box-sizing: border-box !important;overflow-wrap: break-word !important;">ka 在网易云音乐的应用实战</span><span style="max-width: 100%;color: rgb(89, 89, 89);font-size: 15px;letter-spacing: 0.5px;box-sizing: border-box !important;overflow-wrap: break-word !important;">：</span><br style="max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;"  /></section><section style="max-width: 100%;font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);line-height: 1.75em;text-align: left;box-sizing: border-box !important;overflow-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;"  /></section><ol class="list-paddingleft-2" style="list-style-type: decimal;"><li style="text-align: left;"><p><span style="max-width: 100%;font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;box-sizing: border-box !important;overflow-wrap: break-word !important;">背景</span></p></li><li style="text-align: left;"><p><span style="max-width: 100%;font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;box-sizing: border-box !important;overflow-wrap: break-word !important;">Flink + Kafka 平台化设计</span></p></li><li style="text-align: left;"><p><span style="max-width: 100%;font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;box-sizing: border-box !important;overflow-wrap: break-word !important;">Kafka 在实时数仓中的应用</span></p></li><li style="text-align: left;"><p><span style="max-width: 100%;font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;box-sizing: border-box !important;overflow-wrap: break-word !important;">问题 &amp; 改进</span></p></li></ol><section style="max-width: 100%;font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);line-height: 1.75em;text-align: left;box-sizing: border-box !important;overflow-wrap: break-word !important;"><br  /></section></section></section></section><section style="box-sizing: border-box;font-size: 16px;"><section style="margin: 20px 0% 10px;text-align: center;box-sizing: border-box;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 5px solid rgb(71, 193, 168);color: rgb(40, 40, 38);font-size: 18px;box-sizing: border-box;"><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">一、背景介绍</strong></p></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><p style="white-space: normal;box-sizing: border-box;"><br style="box-sizing: border-box;"  /></p></section></section><section style="line-height: 1.75em;text-align: left;"><span style="color: rgb(0, 122, 170);"><strong><span style="color: rgb(0, 122, 170);font-size: 15px;letter-spacing: 0.5px;">（一）流平台通用框架</span></strong></span><br  /></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">目前流平台通用的架构一般来说包括消息队列、计算引擎和存储三部分，通用架构如下图所示。客户端或者 web 的 log 日志会被采集到消息队列；计算引擎实时计算消息队列的数据；实时计算结果以 Append 或者 Update 的形式存放到实时存储系统中去。</span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">目前，我们常用的消息队列是 Kafka，计算引擎一开始我们采用的是 Spark Streaming，随着 Flink 在流计算引擎的优势越来越明显，我们最终确定了 Flink 作为我们统一的实时计算引擎。</span></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><shape type="#_x0000_t75" filled="f"><imagedata title="image1"></imagedata></shape></section><p style="text-align: center;"><img class="rich_pages js_insertlocalimg wxw-img" data-ratio="0.5904761904761905" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6ayMF4WbgtsQSb4RPQ4eU6w81mZMUDmRaLlhWAaDmVV49o14cQWclyaiclDyxwqib2sgS6w20OV8pg/640?wx_fmt=png" data-type="png" data-w="1050" style=""  /></p><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="color: rgb(0, 122, 170);"><strong><span style="font-size: 15px;letter-spacing: 0.5px;">（二）为什么选 Kafka？</span></strong></span><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"></span></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">Kafka 是一个比较早的消息队列，但是它是一个非常稳定的消息队列，有着众多的用户群体，网易也是其中之一。我们考虑 Kafka 作为我们消息中间件的主要原因如下：</span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><ul class="list-paddingleft-2" style="list-style-type: disc;"><li><p><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">高吞吐，低延迟：每秒几十万 QPS 且毫秒级延迟；</span></p></li><li><p><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">高并发：支持数千客户端同时读写；</span></p></li><li><p><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">容错性，可高性：支持数据备份，允许节点丢失；</span></p></li><li><p><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">可扩展性：支持热扩展，不会影响当前线上业务。</span></p></li></ul><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="color: rgb(0, 122, 170);"><strong><span style="font-size: 15px;letter-spacing: 0.5px;">（三）为什么选择 Flink？</span></strong></span><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"></span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">Apache Flink 是近年来越来越流行的一款开源大数据流式计算引擎，它同时支持了批处理和流处理，考虑 Flink 作为我们流式计算引擎的主要因素是：</span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><ul class="list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">高吞吐，低延迟，高性能；</span></p></li><li><p style="text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">高度灵活的流式窗口；</span></p></li><li><p style="text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">状态计算的 Exactly-once 语义；</span></p></li><li><p style="text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">轻量级的容错机制；</span></p></li><li><p style="text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">支持 EventTime 及乱序事件；</span></p></li><li><p style="text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">流批统一引擎。</span></p></li></ul><p><br  /></p><section style="line-height: 1.75em;text-align: left;"><span style="color: rgb(0, 122, 170);"><strong><span style="color: rgb(0, 122, 170);font-size: 15px;letter-spacing: 0.5px;">（四）Kafka + Flink 流计算体系</span></strong></span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">基于 Kafka 和 Flink 的在消息中间件以及流式计算方面的耀眼表现，于是产生了围绕 Kafka 及 Flink 为基础的流计算平台体系，如下图所示：基于 APP、web 等方式将实时产生的日志采集到 Kafka，然后交由 Flink 来进行常见的 ETL，全局聚合以及Window 聚合等实时计算。</span></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><p style="text-align: center;"><img class="rich_pages js_insertlocalimg wxw-img" data-ratio="0.6107784431137725" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6ayMF4WbgtsQSb4RPQ4eU6ibJZicmEicWZuIOm9q5L5Nyh2jqoOwb51Z8ZYd7uUZ5Y33Y1VNtbn6a4w/640?wx_fmt=png" data-type="png" data-w="1002" style=""  /></p><section style="line-height: 1.75em;text-align: left;"><span style="color: rgb(0, 122, 170);"><strong><span style="color: rgb(0, 122, 170);font-size: 15px;letter-spacing: 0.5px;"></span></strong></span></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="color: rgb(0, 122, 170);"><strong><span style="color: rgb(0, 122, 170);font-size: 15px;letter-spacing: 0.5px;">（五）网易云音乐使用 Kafka 的现状</span></strong></span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">目前我们有 10+个 Kafka 集群，各个集群的主要任务不同，有些作为业务集群，有些作为镜像集群，有些作为计算集群等。当前 Kafka 集群的总节点数达到 200+，单 Kafka 峰值 QPS 400W+。目前，网易云音乐基于 Kafka+Flink 的实时任务达到了 500+。</span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><section style="box-sizing: border-box;font-size: 16px;"><section style="margin: 20px 0% 10px;text-align: center;box-sizing: border-box;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 5px solid rgb(71, 193, 168);color: rgb(40, 40, 38);font-size: 18px;box-sizing: border-box;"><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">二、Flink+Kafka 平台化设计</strong></p></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><p style="white-space: normal;box-sizing: border-box;"><br  /></p></section></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">基于以上情况，我们想要对 Kafka+Flink 做一个平台化的开发，减少用户的开发成本和运维成本。实际上在 2018 年的时候我们就开始基于 Flink 做一个实时计算平台，Kafka 在其中发挥着重要作用，今年，为了让用户更加方便、更加容易的去使用 Flink 和 Kafka，我们进行了重构。</span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">基于 Flink 1.0 版本我们做了一个 Magina 版本的重构，在 API 层次我们提供了 Magina SQL 和 Magina SDK 贯穿 DataStream 和 SQL 操作；然后通过自定义 Magina SQL Parser 会把这些 SQL 转换成 Logical Plan，在将 LogicalPlan 转化为物理执行代码，在这过程中会去通过 catalog 连接元数据管理中心去获取一些元数据的信息。我们在 Kafka 的使用过程中，会将 Kafka 元数据信息登记到元数据中心，对实时数据的访问都是以流表的形式。在 Magina 中我们对 Kafka 的使用主要做了三部分的工作：</span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><ul class="list-paddingleft-2" style="list-style-type: disc;"><li><p><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">集群 catalog 化；</span></p></li><li><p><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">Topic 流表化；</span></p></li><li><p><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">Message Schema 化。</span></p></li></ul><section style="line-height: 1.75em;text-align: left;"><br  /></section><p style="text-align: center;"><img class="rich_pages js_insertlocalimg wxw-img" data-ratio="0.5498547918683446" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6ayMF4WbgtsQSb4RPQ4eU65YcjXA9ZmhGibwoBKquFYVwPSxXbG0ia7tkVv4UEhohkBXWz50k9jEnA/640?wx_fmt=png" data-type="png" data-w="1033" style="width: 444px;height: 244px;"  /></p><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">用户可以在元数据管理中心登记不同的表信息或者 catalog 信息等，也可以在 DB 中创建和维护 Kafka 的表，用户在使用的过程只需要根据个人需求使用相应的表即可。下图是对 Kafka 流表的主要引用逻辑。</span></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><p style="text-align: center;"><img class="rich_pages js_insertlocalimg wxw-img" data-ratio="0.5328125" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6ayMF4WbgtsQSb4RPQ4eU6PVUn5vicAu72RqCuGwns7jml2cwcDPO5N2pKTECCsLFs1XjRFQNI3xQ/640?wx_fmt=png" data-type="png" data-w="1280" style=""  /></p><section style="box-sizing: border-box;font-size: 16px;"><section style="margin: 20px 0% 10px;text-align: center;box-sizing: border-box;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 5px solid rgb(71, 193, 168);color: rgb(40, 40, 38);font-size: 18px;box-sizing: border-box;"><p style="box-sizing: border-box;"><br  /></p><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">三、Kafka 在实时数仓中的应用</strong></p></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><p style="white-space: normal;box-sizing: border-box;"><br  /></p></section></section><section style="line-height: 1.75em;text-align: left;"><span style="color: rgb(0, 122, 170);"><strong><span style="color: rgb(0, 122, 170);font-size: 15px;letter-spacing: 0.5px;">（一）在解决问题中发展</span></strong></span></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">Kafka 在实时数仓使用的过程中，我们遇到了不同的问题，中间也尝试了不同的解决办法。</span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">在平台初期， 最开始用于实时计算的只有两个集群，且有一个采集集群，单 Topic 数据量非常大；不同的实时任务都会消费同一个大数据量的 Topic，Kafka 集群 IO 压力异常大；</span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">因此，在使用的过程发现 Kafka 的压力异常大，经常出现延迟、I/O 飙升。</span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">我们想到把大的 Topic 进行实时分发来解决上面的问题，基于 Flink 1.5 设计了如下图所示的数据分发的程序，也就是实时数仓的雏形。基于这种将大的 Topic 分发成小的 Topic 的方法，大大减轻了集群的压力，提升了性能，另外，最初使用的是静态的分发规则，后期需要添加规则的时候要进行任务的重启，对业务影响比较大，之后我们考虑了使用动态规则来完成数据分发的任务。</span></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><p style="text-align: center;"><img class="rich_pages js_insertlocalimg wxw-img" data-ratio="0.5139130434782608" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6ayMF4WbgtsQSb4RPQ4eU6z22y3Ez2UQ3BQqvrpqK1VuXKsd0ibQicPTEuCmpOx1Zj6PsWpYrLbtww/640?wx_fmt=png" data-type="png" data-w="1150" style=""  /></p><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">解决了平台初期遇到的问题之后，在平台进阶过程中 Kafka 又面临新的问题：</span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><ul class="list-paddingleft-2" style="list-style-type: disc;"><li style="text-align: left;"><p><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">虽然进行了集群的扩展，但是任务量也在增加，Kafka 集群压力仍然不断上升；</span></p></li><li style="text-align: left;"><p><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">集群压力上升有时候出现 I/O 相关问题，消费任务之间容易相互影响；</span></p></li><li style="text-align: left;"><p><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">用户消费不同的 Topic 过程没有中间数据的落地，容易造成重复消费；</span></p></li><li style="text-align: left;"><p><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">任务迁移 Kafka 困难。</span></p></li></ul><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">针对以上问题，我们进行了如下图所示的 Kafka 集群隔离和数据分层处理。其过程简单来说，将集群分成 DS 集群、日志采集集群、分发集群，数据通过分发服务分发到 Flink 进行处理，然后通过数据清洗进入到 DW 集群，同时在 DW 写的过程中会同步到镜像集群，在这个过程中也会利用 Flink 进行实时计算的统计和拼接，并将生成的 ADS 数据写入在线 ADS 集群和统计 ADS 集群。通过上面的过程，确保了对实时计算要求比较高的任务不会受到统计报表的影响。</span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><p style="text-align: center;"><img class="rich_pages js_insertlocalimg wxw-img" data-croporisrc="https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6ayMF4WbgtsQSb4RPQ4eU6SsqxN4qILM9RzfFNuS1P6SkszVO1tdH5MnfKX4ibHjZgGIfPzhAGzsw/640?wx_fmt=png" data-cropx1="24.290657439446367" data-cropx2="1080" data-cropy1="91.55709342560553" data-cropy2="571.7647058823529" data-ratio="0.45549242424242425" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ayMF4WbgtsQSb4RPQ4eU6UhCE6gQqIdWZcrgjU9upXjbxDQNQic11otQRtj1Yib2WjWtyQRKE5eibg/640?wx_fmt=jpeg" data-type="jpeg" data-w="1056" style="width: 565px;height: 257px;"  /></p><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">通过上面的过程，确保了对实时计算要求比较高的任务不会受到统计报表的影响。但是我们分发了不同的集群以后就不可避免的面临新的问题：</span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><ul class="list-paddingleft-2" style="list-style-type: disc;"><li><p><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">如何感知 Kafka 集群状态？</span></p></li><li><p><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">如何快速分析 Job 消费异常？</span></p></li></ul><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">针对上面两个问题，我们做了一个 Kafka 监控系统，其监控分为如下两个维度，这样在出现异常的时候就可以进行具体判断出现问题的详细情况：</span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><ul class="list-paddingleft-2" style="list-style-type: disc;"><li style="text-align: left;"><p><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">集群概况的监控：可以看到不同集群对应的 Topic 数量以及运行任务数量，以及每个 Topic 消费任务数据量、数据流入量、流入总量和平均每条数据大小；</span></p></li><li style="text-align: left;"><p><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">指标监控：可以看到 Flink 任务以及对应的 Topic、GroupID、所属集群、启动时间、输入带宽、InTPS、OutTPS、消费延迟以及 Lag 情况。</span></p></li></ul><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="color: rgb(0, 122, 170);"><strong><span style="color: rgb(0, 122, 170);font-size: 15px;letter-spacing: 0.5px;">（二）Flink + Kafk</span></strong></span><strong style="color: rgb(0, 122, 170);"><span style="font-size: 15px;letter-spacing: 0.5px;">a 在 Lambda 架构下的运用</span></strong></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">流批统一是目前非常火的概念，很多公司也在考虑这方面的应用，目前常用的架构要么是 Lambda 架构，要么是 Kappa 架构。对于流批统一来讲需要考虑的包括存储统一和计算引擎统一，由于我们当前基建没有统一的存储，那么我们只能选择了 Lamda 架构。</span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">下图是基于 Flink 和 Kafka 的 Lambda 架构在云音乐的具体实践，上层是实时计算，下层是离线计算，横向是按计算引擎来分，纵向是按实时数仓来区分。</span></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><img data-backh="246" data-backw="548" data-croporisrc="https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6ayMF4WbgtsQSb4RPQ4eU6j4hricJYSO6ADBAWv1iblYx5LOCBVNxG4M4QwEOzy20FrTDibvubpwRZw/640?wx_fmt=png" data-cropx1="7.474048442906574" data-cropx2="1076.2629757785467" data-cropy1="1.8685121107266434" data-cropy2="474.6020761245674" data-ratio="0.441534144059869" src="https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ayMF4WbgtsQSb4RPQ4eU6lc3qqLCSyfGu9MkpdibWIVPXTPMD7DprWLX7WgUfQhZsk0D31GJAXUQ/640?wx_fmt=jpeg" data-type="jpeg" data-w="1069" style="width: 572px;height: 253px;" class="rich_pages wxw-img"  /></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="box-sizing: border-box;font-size: 16px;"><section style="margin: 20px 0% 10px;text-align: center;box-sizing: border-box;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 5px solid rgb(71, 193, 168);color: rgb(40, 40, 38);font-size: 18px;box-sizing: border-box;"><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">四、问题&amp;改进</strong></p></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><p style="white-space: normal;box-sizing: border-box;"><br  /></p></section></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">在具体的应用过程中，我们也遇到了很多问题，最主要的两个问题是：</span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><ul class="list-paddingleft-2" style="list-style-type: disc;"><li><p><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">多 Sink 下 Kafka Source 重复消费问题；</span></p></li><li><p><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">同交换机流量激增消费计算延迟问题。</span></p></li></ul><p><br  /></p><section style="line-height: 1.75em;text-align: left;"><span style="color: rgb(0, 122, 170);"><strong><span style="color: rgb(0, 122, 170);font-size: 15px;letter-spacing: 0.5px;">（一）多 Sink 下 Kafka Source 重复消费问题</span></strong></span></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">Magina 平台上支持多 Sink，也就是说在操作的过程中可以将中间的任意结果插入到不同的存储中。这个过程中就会出现一个问题，比如同一个中间结果，我们把不同的部分插入到不同的存储中，那么就会有多条 DAG，虽然都是临时结果，但是也会造成 Kafka Source 的重复消费，对性能和资源造成极大的浪费。</span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">于是我们想，是否可以避免临时中间结果的多次消费。在 1.9 版本之前，我们进行了 StreamGraph 的重建，将三个 DataSource 的 DAG 进行了合并；在 1.9 版本，Magina 自己也提供了一个查询和 Source 合并的优化；但是我们发现如果是在同一个 data update 中有对同一个表的多个 Source 的引用，它自己会合并，但是如果不是在同一个 data update 中，是不会立即合并的，于是在 1.9 版本之后中我们对 modifyOperations 做了一个 buffer 来解决这个问题。</span></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><p style="text-align: center;"><img class="rich_pages js_insertlocalimg wxw-img" data-ratio="0.5679144385026738" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6ayMF4WbgtsQSb4RPQ4eU6iasyIqVcMFcGkEwFc5iaZe7T3nUCOOnE7abVIGXnSLryYg6XBWPyQfBQ/640?wx_fmt=png" data-type="png" data-w="935" style=""  /></p><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="color: rgb(0, 122, 170);"><strong><span style="color: rgb(0, 122, 170);font-size: 15px;letter-spacing: 0.5px;">（二）同交换机流量激增消费计算延迟问题</span></strong></span></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">这个问题是最近才出现的问题，也可能不仅仅是同交换机，同机房的情况也可能。在同一个交换机下我们部署了很多机器，一部分机器部署了 Kafka 集群，还有一部分部署了 Hadoop 集群。在 Hadoop 上面我们可能会进行 Spark、Hive 的离线计算以及 Flink 的实时计算，Flink 也会消费 Kafka 进行实时计算。在运行的过程中我们发现某一个任务会出现整体延迟的情况，排查过后没有发现其他的异常，除了交换机在某一个时间点的浏览激增，进一步排查发现是离线计算的浏览激增，又因为同一个交换机的带宽限制，影响到了 Flink 的实时计算。</span></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><p style="text-align: center;"><img class="rich_pages js_insertlocalimg wxw-img" data-ratio="0.5737571312143439" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6ayMF4WbgtsQSb4RPQ4eU6ZXyHs4pKCvJfeibibhmLUR1sr8aWkNG7qmu15lxPlkcm1BKlmFjBOvPA/640?wx_fmt=png" data-type="png" data-w="1227" style=""  /></p><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">为解决这个问题，我们就考虑要避免离线集群和实时集群的相互影响，去做交换机部署或者机器部署的优化，比如离线集群单独使用一个交换机，Kafka 和 Flink 集群也单独使用一个交换机，从硬件层面保证两者之间不会相互影响。</span></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"><br  /></span></section><section style="box-sizing: border-box;font-size: 16px;"><section style="margin: 20px 0% 10px;text-align: center;box-sizing: border-box;" powered-by="xiumi.us"><section style="padding: 3px;display: inline-block;border-bottom: 5px solid rgb(71, 193, 168);color: rgb(40, 40, 38);font-size: 18px;box-sizing: border-box;"><p style="box-sizing: border-box;"><strong style="box-sizing: border-box;">五、Q &amp; A</strong></p></section></section><section style="box-sizing: border-box;" powered-by="xiumi.us"><p style="white-space: normal;box-sizing: border-box;"><span style="color: rgb(89, 89, 89);font-size: 15px;letter-spacing: 0.5px;text-align: left;"></span><br  /></p></section></section><section style="line-height: 1.75em;text-align: left;"><strong><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">Q1：Kafka 在实时数仓中的数据可靠吗？</span></strong><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"></span></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">A1：这个问题的答案更多取决于对数据准确性的定义，不同的标准可能得到不同的答案。自己首先要定义好数据在什么情况下是可靠的，另外要在处理过程中有一个很好的容错机制。</span></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><strong><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">Q2：我们在学习的时候如何去学习这些企业中遇到的问题？如何去积累这些问题？</span></strong><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"></span></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">A2：个人认为学习的过程是问题推动，遇到了问题去思考解决它，在解决的过程中去积累经验和自己的不足之处。</span></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><strong><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">Q3：你们在处理 Kafka 的过程中，异常的数据怎么处理，有检测机制吗？</span></strong><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;"></span></section><section style="line-height: 1.75em;text-align: left;"><br  /></section><section style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(89, 89, 89);letter-spacing: 0.5px;">A3：在运行的过程中我们有一个分发的服务，在分发的过程中我们会根据一定的规则来检测哪些数据是异常的，哪些是正常的，然后将异常的数据单独分发到一个异常的 Topic 中去做查询等，后期用户在使用的过程中可以根据相关指标和关键词到异常的 Topic 中去查看这些数据。</span></section><section style="max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;min-height: 1em;background-color: rgb(255, 255, 255);text-align: center;line-height: 1.75em;box-sizing: border-box !important;overflow-wrap: break-word !important;"><br  /></section><p style="text-align: center;"><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzU2ODQ3NjYyMA==&amp;mid=2247487139&amp;idx=2&amp;sn=e8b128885985f7c9fc0bce3b8d5c92d2&amp;chksm=fc8c1800cbfb9116cbb6b961fa59386f46a98a8a0a59ee134496c4df852707febfac453882e6&amp;scene=21#wechat_redirect" textvalue="你已选中了添加链接的内容" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="1"><span class="js_jump_icon h5_image_link" data-positionback="static" style="inset: auto;margin: 0px;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.4255555555555556" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/PL10rfzHicsg7x8cV1KM4GIiay2P8GficL7yLPx5BhXe6mYmPPm0ZKI5LXX5c0BmzkcUZylicVSvRt0Yf43iaoG04Yg/640?wx_fmt=png" data-type="png" data-w="900" style="margin: 0px;"  /></span></a></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-ratio="0.5555555555555556" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/PL10rfzHicsgYic9icrPjCqicQZOqicicQRjOr9ka3KSCgElNV1HLd89YxT5NMTUmMwhGyE7KFVo2I11Rta7icUMP2muA/640?wx_fmt=png" data-type="png" data-w="900" style=""  /></p><section style="max-width: 100%;letter-spacing: 0.544px;white-space: normal;font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;min-height: 1em;background-color: rgb(255, 255, 255);text-align: center;line-height: 1.75em;box-sizing: border-box !important;overflow-wrap: break-word !important;"><br  /></section><div class="msg_source_url"><a href="https://mp.weixin.qq.com/s/RykdGWsESRNhq9r7q2f-CA?scene=25#wechat_redirect" target="_blank">阅读原文</a></div></content><div class="msg_source_url"><a href="https://mp.weixin.qq.com/s/RykdGWsESRNhq9r7q2f-CA?scene=25#wechat_redirect" target="_blank">阅读原文</a></div>
</div>
</body>
</html>