<html>
<head>
<title></title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0,viewport-fit=cover">
<style>
*{margin:0;padding:0}html{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;line-height:1.6}img{z-index:999;position:relative;max-width:100%;margin:10px 0;}body{letter-spacing:.034em}h1,h2,h3,h4,h5,h6{font-weight:400;font-size:16px}a{color:#576b95;text-decoration:none;-webkit-tap-highlight-color:rgba(0,0,0,0)}td,th{word-wrap:break-word;padding:5px 10px;border:1px solid #DDD;}table{margin-bottom:10px;border-collapse:collapse;display:table;width:100%!important;}.appmsg_skin_default .rich_media_area_primary{background-color:#fff}.appmsg_skin_default .rich_media_area_primary .weui-loadmore_line .weui-loadmore__tips{background-color:#fff}.rich_media_area_primary{padding:20px 16px 12px;background-color:#fafafa}@media (max-width:375px){.rich_media_area_primary{padding:20px 60px 15px 60px}.rich_media_area_extra{padding:0 60px 21px 60px}}@media (min-width:1024px){.rich_media_area_primary_inner,.rich_media_area_extra_inner,body{max-width:677px;margin-left:auto;margin-right:auto}.rich_media_area_primary{padding-top:32px}}.rich_media{padding:20px;overflow:hidden;}.appmsg_skin_default .rich_media_area_primary{background-color:#fff}.appmsg_skin_default .rich_media_area_primary .weui-loadmore_line .weui-loadmore__tips{background-color:#fff}@media screen and (min-width:1024px){.rich_media_area_primary_inner,.rich_media_area_extra_inner{max-width:677px;margin-left:auto;margin-right:auto}.rich_media_area_primary{padding-top:32px}}.rich_media_content{overflow:hidden;color:#333;font-size:17px;word-wrap:break-word;-webkit-hyphens:auto;-ms-hyphens:auto;hyphens:auto;text-align:justify;position:relative;z-index:0}.rich_media_content *{max-width:100%!important;box-sizing:border-box!important;-webkit-box-sizing:border-box!important;word-wrap:break-word!important}.rich_media_content p{clear:both;min-height:1em}.rich_media_content em{font-style:italic}.rich_media_content fieldset{min-width:0}.rich_media_content .list-paddingleft-1,.rich_media_content .list-paddingleft-2,.rich_media_content .list-paddingleft-3{padding-left:2.2em}.rich_media_content .list-paddingleft-1 .list-paddingleft-2,.rich_media_content .list-paddingleft-2 .list-paddingleft-2,.rich_media_content .list-paddingleft-3 .list-paddingleft-2{padding-left:30px}.rich_media_content .list-paddingleft-1{padding-left:1.2em}.rich_media_content .list-paddingleft-3{padding-left:3.2em}.rich_media_content .code-snippet,.rich_media_content .code-snippet__fix{max-width:1000%!important}.rich_media_content .code-snippet *,.rich_media_content .code-snippet__fix *{max-width:1000%!important}.rich_media_title{font-size:22px;line-height:1.4;margin-bottom:13px;padding-bottom:13px;border-bottom:1px solid #e7e7eb;}@supports(-webkit-overflow-scrolling:touch){.rich_media_title{font-weight:700}}.rich_media_meta{display:inline-block;vertical-align:middle;padding:0 0 10px 0;font-size:15px;-webkit-tap-highlight-color:rgba(0,0,0,0)}.rich_media_meta.icon_appmsg_tag{margin-right:0px}.rich_media_meta.meta_tag_text{margin-right:0}.rich_media_meta_list em{font-style:normal}.rich_media_meta_text{color:#a5a5a5;}p{margin:0;}.msgBox{margin-top:20px;padding-top:20px;padding-left:50px;overflow:hidden;border-top:2px dashed #09a2ff;}.msg{padding-top:7px;clear:both;}.msgBody{float:right;width:100%;margin-left:55px;padding-bottom:15px;border-bottom:1px dashed #e0e0e0;}.userHeadImg{float:left;margin-left:-50px;}.userHeadImg img{width:40px;height:40px;margin-right:10px;border-radius:3px;}.userName{color:#888888;line-height:24px;font-size:14px;margin:5px 0 5px 0;height:24px;}.replyBody,.autherBody{color:#565656;font-size:15px;}.replyIcon{border-left:4px solid #33ab01;margin-right:5px;}.ad{text-decoration:none;color:#d6d4d4;font-size:12px;}.msgBodyReply{padding-top:5px;}.userName span{float:right;color:#afafaf;font-size:14px;}code{text-align:left;font-size:14px;display:block;white-space:pre;display:-webkit-box;display:-webkit-flex;display:flex;position:relative;}.code-snippet__fix{font-size:14px;margin:10px 0;display:block;color:#333;position:relative;background-color:rgba(0,0,0,0.03);border:1px solid #f0f0f0;border-radius:2px;display:-webkit-box;display:-webkit-flex;display:flex;padding-left:25px;line-height:26px}.code-snippet__fix code{text-align:left;font-size:14px;display:block;white-space:pre;display:-webkit-box;display:-webkit-flex;display:flex;position:relative;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace}.code-snippet__comment,.code-snippet__quote{color:#afafaf;font-style:italic}.code-snippet__keyword,.code-snippet__selector-tag,.code-snippet__subst{color:#ca7d37}.code-snippet__number,.code-snippet__literal,.code-snippet__variable,.code-snippet__template-variable,.code-snippet__tag .code-snippet__attr{color:#0e9ce5}.code-snippet__string,.code-snippet__doctag{color:#d14}.code-snippet__title,.code-snippet__section,.code-snippet__selector-id{color:#d14}.code-snippet__subst{font-weight:normal}.code-snippet__type,.code-snippet__class .code-snippet__title{color:#0e9ce5}.code-snippet__tag,.code-snippet__name,.code-snippet__attribute{color:#0e9ce5;font-weight:normal}.code-snippet__regexp,.code-snippet__link{color:#ca7d37}.code-snippet__symbol,.code-snippet__bullet{color:#d14}.code-snippet__built_in,.code-snippet__builtin-name{color:#ca7d37}.code-snippet__meta{color:#afafaf}.code-snippet__deletion{background:#fdd}.code-snippet__addition{background:#dfd}.code-snippet__emphasis{font-style:italic}.code-snippet__strong{font-weight:bold}.account_avatar{width:40px;height:40px;padding:0;}.account_info{display:-webkit-box;display:-webkit-flex;display:flex;-webkit-box-align:center;-webkit-align-items:center;padding:20px 0;align-items:center}.flex_bd{padding-left:14px;}.account_nickname{display:inline-block;vertical-align:middle;line-height:1.2;color:#576b95;font-size:14px}.account_desc{overflow:hidden;text-overflow:ellipsis;display:-webkit-box;-webkit-box-orient:vertical;-webkit-line-clamp:1;color:rgba(0,0,0,0.3);font-size:14px;line-height:1.2;padding-top:.4em}.msg_source_url{text-align:left;word-break:break-all;margin-top:20px;}.msg_source_url a{padding-right:10px;}.msg_source_url .url_text{color:#a8a8a8;}.video-desc{font-size:14px;margin-top:15px;color:#6c6c6c;}.msg_source_url{text-align:left;}.original_primary_card_tips{color:rgba(0,0,0,0.3);line-height:1.4;font-size:15px;}.weui-flex__item{margin-bottom:20px;padding:20px 16px;margin-top:16px;line-height:1.4;align-items:center;background-color:#f7f7f7;border-radius:8px;position:relative;}.original_primary_desc{color:rgba(0,0,0,0.5);font-size:14px;padding-top:4px;width:auto;overflow:hidden;text-overflow:ellipsis;}.msgBodyReplyList{border-top:1px solid #e1e1e1;margin-top:10px;}.msgBodyReplyListTop{border-top:0;}.reply_like_num{float:right;font-size:14px;color:#c7c7c7;}.msgData{margin-top:20px;color:#626262;}.msgData span{font-size:14px;padding-right:15px;}.msgData .likes{float:right;padding-right:0;}.js_text_content p{font-size:18px;}.rich_media_meta_link{font-size:15px;}blockquote {padding-left: 10px;border-left: 3px solid #dbdbdb;color: rgba(0,0,0,0.5);font-size: 15px;padding-top: 4px;margin: 1em 0;}.video_iframe{width:500px;height:400px;}.blockquote_info{color:#b5b5b5;margin-top:10px;}#copyright_logo{color:#bdbdbd;}.rich_media_meta_list{margin-bottom:10px;}.reprint{background:#efefef;border-radius:5px;padding:8px;color:#1f1f1f;}.reprint a{word-break:break-all;}.topic{color:#8e8e8e;background:#f7f7f7;border-radius:5px;padding:10px 8px;}.topic a{padding-right:5px;}.topic p{margin-bottom:5px;}
</style>
<link href="https://www.juyifx.cn/config/css/wxArticle.css" rel="stylesheet"/>
</head><script>
var data={"mp":"数据治理体系","title":"监督学习、无监督学习与强化学习","time":"2023-06-06 07:33:42","timeStamp":"1686008022"};
</script>
<body>
<div class="rich_media"><h1 class="rich_media_title" id="activity-name"><a href="http://mp.weixin.qq.com/s?__biz=MzA3NjIzNjMwOA==&mid=2247495570&idx=1&sn=4bec415842617d0341877f4733347d2b&chksm=9f66fce9a81175ff9e923135ec04aeac1def612d0662e13defe6a1cc72f4e9fd2a0f6879d81e#rd" target="_blank">监督学习、无监督学习与强化学习</a></h1><div id="meta_content" class="rich_media_meta_list"><span class="rich_media_meta rich_media_meta_nickname" id="profileBt"><a href="javascript:void(0);" class="wx_tap_link js_wx_tap_highlight weui-wa-hotarea" id="js_name">数据治理体系&nbsp;&nbsp;</a></span><em id="publish_time" class="rich_media_meta rich_media_meta_text">2023-06-06 07:33:42</em></div><content><div class="topic"><p>收录于话题</p><p><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzA3NjIzNjMwOA==&action=getalbum&album_id=2948956974820622337#wechat_redirect" title="数据智能" target="_blank">#数据智能</a></p></div><section class="mp_profile_iframe_wrp" data-mpa-powered-by="yiban.io"><mp-common-profile class="custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-weuitheme="light" data-id="MzA3NjIzNjMwOA==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/hXibVSNciaXhzia07WkYkDfaRxHUiaDaNc5x3xTNO1RlNBRhPnxpEzoemhsn7ofat4pVwVgOktaveEtu6IKzzLONQQ/0?wx_fmt=png" data-nickname="数据治理体系" data-alias="DGsystem" data-signature="持续完善数据治理实战体系，数据仓库、标签、指标体系，实现业务数字化，数字资产化，资产业务化，资产资本化；回归业务场景的数字化案例才最具参考价值，最容易理解和借鉴的。关注我，和您一起终身学习。" data-from="0" data-weui-theme="light"></mp-common-profile></section><section style="text-indent: 2em;"><span style="font-size: 16px;">机器学习算法可以分为3种：有监督学习（Supervised Learning）、无监督学习（Unsupervised Learning）和强化学习（Reinforcement Learning）。</span><strong><span style="font-size: 16px;text-indent: 2em;">监督学习</span></strong><span style="font-size: 16px;text-indent: 2em;">是模型利用有标签数据进行训练，主要解决回归与分类问题。</span><strong><span style="font-size: 16px;text-indent: 2em;">无监督学习</span></strong><span style="font-size: 16px;text-indent: 2em;">是模型利用无标签数据进行训练，主要完成聚类与关联问题。<strong>强化学习</strong>是用于描述和解决智能体（agent）在与环境的交互过程中通过学习策略以达成回报最大化或实现特定目标的问题。除此之外，结合监督学习与无监督学习形成了半监督学习，而半监督学习是属于弱监督学习中的一种形式。</span></section><section style="text-indent: 2em;text-align: center;"><span style="font-size: 16px;text-indent: 2em;"><img class="rich_pages wxw-img" data-ratio="0.9919354838709677" data-type="png" data-w="868" style="width: 260px;height: auto !important;" src="https://mmbiz.qpic.cn/mmbiz_png/eUK9xbyE6CgBtjQtWUgPdj5mbpuQl0F4EAn98Dc6zMU1GibIsVa6SSamjnLLicQZBj3IAInB3BeOLWnjW8CRXxmA/640?wx_fmt=png"  /></span></section><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="0.6759884281581485" data-s="300,640" data-type="png" data-w="1037" style="width: 402px;height: auto !important;" src="https://mmbiz.qpic.cn/mmbiz_png/eUK9xbyE6CgBtjQtWUgPdj5mbpuQl0F4xKmpZPE3VbPESUpyaQASHFaiajzYvLwJloicl17y9SBSbp5qe27TErYQ/640?wx_fmt=png"  /></p><section style="text-align: center;text-indent: 0em;"><span style="font-size: 16px;"><strong>一、监督学习</strong></span></section><section style="text-align: left;text-indent: 0em;"><span style="font-size: 16px;"><strong>1. 概念</strong><br  /></span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">监督学习是机器学习的一种类型，本质是机器使用“标记好”的训练数据进行训练，并基于该数据，机器预测输出。标记的数据意味着一些输入数据已经用正确的输出标记。在监督学习中，提供给机器的训练数据充当监督者，教导机器正确预测输出。它应用了与学生在老师的监督下学习相同的概念。监督学习是向机器学习模型提供输入数据和正确输出数据的过程。监督学习算法的目的是找到一个映射函数来映射输入变量（x）和输出变量（y）。在现实世界中，监督学习可用于风险评估、图像分类、欺诈检测、垃圾邮件过滤等。</span></section><section style="text-indent: 0em;"><span style="font-size: 16px;"><strong>2. 运作方式</strong><br  /></span></section><section style="outline: 0px;margin-bottom: 16px;font-size: 16px;color: rgb(77, 77, 77);line-height: 26px;overflow: auto hidden;font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;text-align: left;white-space: normal;background-color: rgb(255, 255, 255);text-indent: 2em;"><span style="font-size: 16px;">在监督学习中，模型使用标记数据集进行训练，其中模型学习每种类型的数据。训练过程完成后，模型会根据测试数据（训练集的子集）进行测试，然后预测输出。以下示例和图表可以很容易地理解监督学习的工作原理：</span><img class="rich_pages wxw-img" data-ratio="0.4847328244274809" data-type="png" data-w="786" height="381" style="text-indent: 2em;color: rgb(51, 51, 51);font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 17px;text-align: justify;height: auto !important;" width="786" src="https://mmbiz.qpic.cn/mmbiz_png/sz9IdlMoOAPibCGEZiaarXSss24EIGibmEEkSLAL8ibCASyF8kPgMItLpnZzB9U8FLCESDUoO0ZxCMVnJkibxgWXUFA/640?wx_fmt=png"  /></section><section style="text-indent: 0em;"><span style="font-size: 16px;"><strong>3<strong style="white-space: normal;">. 学习步骤</strong></strong><strong style="white-space: normal;"></strong></span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">（1）首先确定训练数据集的类型；</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">（2）收集/收集标记的训练数据（一般可能需要手动标记）；</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">（3）将训练数据集拆分为训练数据集、测试数据集和验证数据集；</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">（4）确定训练数据集的输入特征，这些特征应该有足够的知识使模型能够准确地预测输出；</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">（5）确定适合模型的算法，如支持向量机、决策树等；</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">（6）在训练数据集上执行算法。有时我们需要验证集作为控制参数，它们是训练数据集的子集；</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">（7）通过提供测试集来评估模型的准确性。如果模型预测出正确的输出，这意味着我们的模型是准确的。</span></section><p><span style="font-size: 16px;"><strong>4<strong style="font-weight: bold;">. 解决问题</strong></strong></span></p><p><span style="font-size: 16px;"><span style="color: rgb(77, 77, 77);font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);">监督学习主要解决两类问题：</span><span style="outline: 0px;font-weight: 700;color: rgb(77, 77, 77);font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);">回归</span><span style="color: rgb(77, 77, 77);font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);">和</span><span style="outline: 0px;font-weight: 700;color: rgb(77, 77, 77);font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);">分类</span><span style="color: rgb(77, 77, 77);font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);">。</span></span></p><p style="outline: 0px;margin-bottom: 16px;font-size: 16px;color: rgb(77, 77, 77);line-height: 26px;overflow: auto hidden;font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;text-align: start;white-space: normal;background-color: rgb(255, 255, 255);text-indent: 2em;"><span style="font-size: 16px;outline: 0px;font-weight: 700;">4.1. 回归</span></p><p style="outline: 0px;margin-bottom: 16px;font-size: 16px;color: rgb(77, 77, 77);line-height: 26px;overflow: auto hidden;font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;text-align: start;white-space: normal;background-color: rgb(255, 255, 255);text-indent: 2em;"><span style="font-size: 16px;"><span style="outline: 0px;font-weight: 700;">如果输入变量和输出变量之间存在关系，则使用回归算法</span>。它用于预测连续变量，例如天气预报、市场趋势等。以下是一些流行的回归算法，它们属于监督学习：</span></p><ul style="outline: 0px;margin-bottom: 24px;list-style-position: initial;list-style-image: initial;font-size: 16px;overflow: auto hidden;color: rgba(0, 0, 0, 0.75);font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;white-space: normal;background-color: rgb(255, 255, 255);" class="list-paddingleft-1"><li style="outline: 0px;margin-top: 8px;margin-left: 32px;list-style: disc;font-size: 16px;"><p><span style="font-size: 16px;">线性回归</span></p></li><li style="outline: 0px;margin-top: 8px;margin-left: 32px;list-style: disc;font-size: 16px;"><p><span style="font-size: 16px;">回归树</span></p></li><li style="outline: 0px;margin-top: 8px;margin-left: 32px;list-style: disc;font-size: 16px;"><p><span style="font-size: 16px;">非线性回归</span></p></li><li style="outline: 0px;margin-top: 8px;margin-left: 32px;list-style: disc;font-size: 16px;"><p><span style="font-size: 16px;">贝叶斯线性回归</span></p></li><li style="outline: 0px;margin-top: 8px;margin-left: 32px;list-style: disc;font-size: 16px;"><p><span style="font-size: 16px;">多项式回归</span></p></li></ul><section style="outline: 0px;margin-bottom: 16px;font-size: 16px;color: rgb(77, 77, 77);line-height: 26px;overflow: auto hidden;font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;text-align: start;white-space: normal;background-color: rgb(255, 255, 255);text-indent: 2em;"><span style="font-size: 16px;outline: 0px;font-weight: 700;">4.2. 分类</span></section><section style="outline: 0px;margin-bottom: 16px;font-size: 16px;color: rgb(77, 77, 77);line-height: 26px;overflow: auto hidden;font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;text-align: start;white-space: normal;background-color: rgb(255, 255, 255);text-indent: 2em;"><span style="text-indent: 2em;">当输出变量是分类时使用分类算法，这意味着有两个类别，例如是 - 否，男性 - 女性，真假等。垃圾邮件过滤，是否为垃圾等。可能用到的算法：</span><span style="font-size: 16px;"><br  /></span></section><ul style="outline: 0px;margin-bottom: 24px;list-style-position: initial;list-style-image: initial;font-size: 16px;overflow: auto hidden;color: rgba(0, 0, 0, 0.75);font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;white-space: normal;background-color: rgb(255, 255, 255);" class="list-paddingleft-1"><li style="outline: 0px;margin-top: 8px;margin-left: 32px;list-style: disc;font-size: 16px;"><p><span style="font-size: 16px;">随机森林</span></p></li><li style="outline: 0px;margin-top: 8px;margin-left: 32px;list-style: disc;font-size: 16px;"><p><span style="font-size: 16px;">决策树</span></p></li><li style="outline: 0px;margin-top: 8px;margin-left: 32px;list-style: disc;font-size: 16px;"><p><span style="font-size: 16px;">逻辑回归</span></p></li><li style="outline: 0px;margin-top: 8px;margin-left: 32px;list-style: disc;font-size: 16px;"><p><span style="font-size: 16px;">支持向量机</span></p></li></ul><p><span style="font-size: 16px;"><strong>5<strong style="font-weight: bold;">. 优缺点</strong></strong></span></p><section style="text-indent: 2em;"><span style="font-size: 16px;color: rgb(0, 0, 0);">优点：在监督学习的帮助下，模型可以根据先前的经验预测输出；在监督学习中，我们可以对对象的类别有一个准确的认识；监督学习模型帮助我们解决各种现实问题，例如欺诈检测、垃圾邮件过滤等。</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;color: rgb(0, 0, 0);">缺点：监督学习模型不适合处理复杂的任务；如果测试数据与训练数据集不同，监督学习无法预测正确的输出；训练需要大量的计算时间；在监督学习中，我们需要足够的关于对象类别的知识。</span></section><section style="text-indent: 0em;white-space: normal;text-align: center;"><span style="font-size: 16px;"><strong>二、无监督学习</strong></span></section><section style="text-indent: 0em;white-space: normal;text-align: left;"><span style="font-size: 16px;"><strong>1.&nbsp;概念</strong><br  /></span></section><section style="white-space: normal;text-indent: 2em;"><span style="font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-size: 16px;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);color: rgb(0, 0, 0);">无监督学习是一种机器学习技术，其中模型不使用训练数据集进行监督。相反，模型本身会从给定数据中找到隐藏的模式和见解。它可以比作在学习新事物时发生在人脑中的学习。它可以定义为：使用未标记的数据集进行训练，并允许在没有任何监督的情况下对该数据进行操作。无监督学习不能直接应用于回归或分类问题，因为与监督学习不同，我们有输入数据但没有相应的输出数据。无监督学习的目标是<span style="outline: 0px;font-weight: 700;font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);">找到数据集的底层结构，根据相似性对数据进行分组，并以压缩格式表示该数据集</span>。示例，假设给定无监督学习算法的输入数据集，其中包含不同类型的猫和狗的图像。该算法从未在给定的数据集上进行过训练，这意味着它对数据集的特征一无所知。无监督学习算法的任务是自行识别图像特征。无监督学习算法将通过根据图像之间的相似性将图像数据集聚类到组中来执行此任务。</span></section><section style="text-indent: 0em;white-space: normal;"><span style="font-size: 16px;"><strong>2. 运作方式</strong><br  /></span></section><section style="text-indent: 2em;"><span style="color: rgb(0, 0, 0);">采用未标记的输入数据，这意味着它没有分类，也没有给出相应的输出。现在，这些未标记的输入数据被输入机器学习模型以对其进行训练。首先，它将解释原始数据以从数据中找到隐藏的模式，然后应用合适的算法，如 k-means 聚类、决策树等。</span></section><p><img class="rich_pages wxw-img" data-ratio="0.4798994974874372" data-type="png" data-w="796" height="382" width="796" style="height: auto !important;" src="https://mmbiz.qpic.cn/mmbiz_png/qosQnVJKPupga1mxIgj1Mub7V7riaU9LvzLEQO4udUXIdTI5qqc4RQMqiblafO89l9OSh7M3fJHC3IBicrbtwuWZw/640?wx_fmt=png"  /></p><section style="text-indent: 0em;white-space: normal;"><span style="font-size: 16px;"><strong>3<strong>.&nbsp;</strong></strong></span><span style="font-size: 16px;color: rgb(0, 0, 0);"><strong><strong>存在原因</strong></strong></span></section><section style="text-indent: 2em;"><span style="font-size: 16px;color: rgb(0, 0, 0);">（1）无监督学习有助于从数据中找到有用的见解；</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;color: rgb(0, 0, 0);">（2）无监督学习与人类通过自己的经验学习思考非常相似，这使得它更接近真正的人工智能；</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;color: rgb(0, 0, 0);">（3）无监督学习适用于未标记和未分类的数据，这使得无监督学习更加重要；</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;color: rgb(0, 0, 0);">（4）在现实世界中，我们并不总是有输入数据和相应的输出，因此为了解决这种情况，我们需要无监督学习；</span></section><p style="white-space: normal;"><span style="font-size: 16px;"><strong>4<strong>. 解决问题</strong></strong></span></p><section style="white-space: normal;text-indent: 2em;"><span style="color: rgb(0, 0, 0);font-size: 16px;"><span style="font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);">无监督学习主要解决两类问题：</span><strong>聚类</strong>和<strong>关联</strong><span style="font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);">。</span></span></section><p style="margin-bottom: 16px;white-space: normal;outline: 0px;font-size: 16px;color: rgb(77, 77, 77);line-height: 26px;overflow: auto hidden;font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);text-indent: 2em;"><span style="outline: 0px;font-weight: 700;color: rgb(0, 0, 0);font-size: 16px;">4.1.&nbsp;<strong style="font-size: 16px;white-space: normal;">聚类</strong></span></p><p style="margin-bottom: 16px;white-space: normal;outline: 0px;font-size: 16px;color: rgb(77, 77, 77);line-height: 26px;overflow: auto hidden;font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);text-indent: 2em;"><span style="color: rgb(0, 0, 0);font-size: 16px;">聚类是一种将对象分组为聚类的方法，使得具有最多相似性的对象保留在一个组中，并且与另一组的对象具有较少或没有相似性。聚类分析发现数据对象之间的共性，并根据这些共性的存在和不存在对它们进行分类。</span></p><section style="margin-bottom: 16px;white-space: normal;outline: 0px;font-size: 16px;color: rgb(77, 77, 77);line-height: 26px;overflow: auto hidden;font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);text-indent: 2em;"><span style="outline: 0px;font-weight: 700;color: rgb(0, 0, 0);font-size: 16px;">4.2.&nbsp;<strong style="font-size: 16px;white-space: normal;">关联</strong></span><br style="outline: 0px;"  /></section><section style="text-indent: 2em;"><span style="font-size: 16px;color: rgb(0, 0, 0);">关联规则是一种无监督学习方法，用于查找大型数据库中变量之间的关系。它确定在数据集中一起出现的项目集。关联规则使营销策略更加有效。例如购买 X 商品（假设是面包）的人也倾向于购买 Y（黄油/果酱）商品。关联规则的一个典型例子是市场篮子分析。</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;color: rgb(0, 0, 0);">无监督学习算法主要有：</span></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><section style="text-indent: 2em;"><span style="font-size: 16px;">K-means 聚类</span></section></li><li><p><span style="font-size: 16px;text-align: justify;">KNN（k-最近邻）</span><br  /></p></li><li><p>层次聚类<br  /></p></li><li><p>异常检测<br  /></p></li><li><p><span style="font-size: 16px;text-align: justify;">神经网络</span><br  /></p></li><li><p><span style="font-size: 16px;text-align: justify;">主成分分析</span><br  /></p></li><li><p><span style="font-size: 16px;text-align: justify;">独立成分分析</span><br  /></p></li><li><p><span style="font-size: 16px;text-align: justify;">先验算法</span><br  /></p></li><li><p><span style="font-size: 16px;text-align: justify;">奇异值分解</span></p></li></ul><p style="white-space: normal;"><span style="font-size: 16px;"><strong>5<strong>.&nbsp;优缺点</strong></strong></span></p><section style="white-space: normal;text-indent: 2em;"><span style="font-size: 16px;color: rgb(0, 0, 0);">优点：与监督学习相比，无监督学习用于更复杂的任务，因为在无监督学习中，我们没有标记的输入数据；无监督学习更可取，因为与标记数据相比，它更容易获得未标记数据。</span></section><section style="white-space: normal;text-indent: 2em;"><span style="font-size: 16px;color: rgb(0, 0, 0);">缺点：无监督学习本质上比监督学习更难，因为它没有相应的输出；无监督学习算法的结果可能不太准确，因为输入数据没有标记，并且算法事先不知道确切的输出。</span></section><section style="text-indent: 0em;white-space: normal;text-align: center;"><span style="font-size: 16px;"><strong>三、强化学习</strong></span></section><section style="text-indent: 0em;white-space: normal;text-align: left;"><span style="font-size: 16px;"><strong>1. 概念</strong><br  /></span></section><section style="white-space: normal;text-indent: 2em;"><span style="font-size: 16px;">又称再励学习、评价学习或增强学习，是机器学习的范式和方法论之一，用于描述和解决智能体（agent）在与环境的交互过程中通过学习策略以达成回报最大化或实现特定目标的问题。换句话说，强化学习是一种学习如何从状态映射到行为以使得获取的奖励最大的学习机制。这样的一个agent需要不断地在环境中进行实验，通过环境给予的反馈（奖励）来不断优化状态-行为的对应关系。因此，反复实验(trial and error）和延迟奖励（delayed reward）是强化学习最重要的两个特征。</span></section><section style="text-indent: 0em;white-space: normal;"><span style="font-size: 16px;"><strong>2. 运作方式</strong><br  /></span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">三种学习方式的区别是：监督学习是机器学习领域研究最多的方法，已经十分成熟，在监督学习的训练集中，每一个样本都含有一个标签，在理想情况下，这个标签通常指代正确的结果。监督学习的任务即是让系统在训练集上按照每个样本所对应的标签推断出应有的反馈机制，进而在未知标签的样本上能够计算出一个尽可能正确的结果，例如我们熟悉的分类与回归问题。在强化学习中的交互问题中却并不存在这样一个普适正确的“标签”，智能体只能从自身的经验中去学习。</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">但是强化学习与同样没有标签的无监督学习也不太一样，无监督学习是从无标签的数据集中发现隐藏的结构，典型的例子就是聚类问题。但是<strong>强化学习的目标是最大化奖励而非寻找隐藏的数据集结构</strong>，尽管用无监督学习的方法寻找数据内在结构可以对强化学习任务起到帮助，但并未从根本上解决最大化奖励的问题。</span><br  /></section><p><strong><span style="font-size: 16px;">3. 强化学习特点</span></strong></p><ul style="outline: 0px;margin-bottom: 24px;list-style-position: initial;list-style-image: initial;font-size: 16px;overflow: auto hidden;color: rgba(0, 0, 0, 0.75);font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;white-space: normal;background-color: rgb(255, 255, 255);" class="list-paddingleft-1"><li style="outline: 0px;margin-top: 8px;margin-left: 32px;list-style: disc;"><p>没有监督者，只有一个奖励信号</p></li><li style="outline: 0px;margin-top: 8px;margin-left: 32px;list-style: disc;"><p>反馈是延迟的而非即时</p></li><li style="outline: 0px;margin-top: 8px;margin-left: 32px;list-style: disc;"><p>具有时间序列性质</p></li><li style="outline: 0px;margin-top: 8px;margin-left: 32px;list-style: disc;"><p>智能体的行为会影响后续的数据</p></li></ul><section style="text-indent: 0em;white-space: normal;"><span style="font-size: 16px;"><strong>4<strong>. 要素与框架</strong></strong></span></section><section style="white-space: normal;text-indent: 2em;"><span style="font-size: 16px;">强化学习系统一般包括四个基本要素：策略（policy），奖励（reward），价值（value）以及环境或者说是模型（model）。接下来我们对这四个要素分别进行介绍。</span></section><section style="text-indent: 2em;"><strong><span style="font-size: 16px;">4.1 策略（Policy）</span></strong></section><section style="text-indent: 2em;"><span style="font-size: 16px;">策略定义了智能体对于给定状态所做出的行为，换句话说，就是一个从状态到行为的映射，事实上状态包括了环境状态和智能体状态，这里我们是从智能体出发的，也就是指智能体所感知到的状态。因此我们可以知道策略是强化学习系统的核心，因为我们完全可以通过策略来确定每个状态下的行为。我们将策略的特点总结为以下三点：</span></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p><span style="font-size: 16px;">策略定义智能体的行为</span></p></li><li><p><span style="font-size: 16px;">它是从状态到行为的映射</span></p></li><li><p><span style="font-size: 16px;">策略本身可以是具体的映射也可以是随机的分布</span></p></li></ul><section style="text-indent: 2em;"><strong><span style="font-size: 16px;">4. 2 奖励（Reward）</span></strong></section><section style="text-indent: 2em;"><span style="font-size: 16px;">奖励信号定义了强化学习问题的目标，在每个时间步骤内，环境向强化学习发出的标量值即为奖励，它能定义智能体表现好坏，类似人类感受到快乐或是痛苦。因此我们可以体会到奖励信号是影响策略的主要因素。我们将奖励的特点总结为以下三点：</span></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p><span style="font-size: 16px;">奖励是一个标量的反馈信号</span></p></li><li><p><span style="font-size: 16px;">它能表征在某一步智能体的表现如何</span></p></li><li><p><span style="font-size: 16px;">智能体的任务就是使得一个时段内积累的总奖励值最大</span></p></li></ul><section style="text-indent: 2em;"><span style="font-size: 16px;"><strong>4.3 价值（Value）</strong></span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">接下来说说价值，或者说价值函数，这是强化学习中非常重要的概念，与奖励的即时性不同，价值函数是对长期收益的衡量。我们常常会说“既要脚踏实地，也要仰望星空”，对价值函数的评估就是“仰望星空”，从一个长期的角度来评判当前行为的收益，而不仅仅盯着眼前的奖励。结合强化学习的目的，我们能很明确地体会到价值函数的重要性，事实上在很长的一段时间内，强化学习的研究就是集中在对价值的估计。我们将价值函数的特点总结为以下三点：</span></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p><span style="font-size: 16px;">价值函数是对未来奖励的预测</span></p></li><li><p><span style="font-size: 16px;">它可以评估状态的好坏</span></p></li><li><p><span style="font-size: 16px;">价值函数的计算需要对状态之间的转移进行分析</span></p></li></ul><section style="text-indent: 2em;"><strong><span style="font-size: 16px;">4.4 环境（模型）</span></strong></section><section style="text-indent: 2em;"><span style="font-size: 16px;">最后说说外界环境，也就是模型（Model），它是对环境的模拟，举个例子来理解，当给出了状态与行为后，有了模型我们就可以预测接下来的状态和对应的奖励。但我们要注意的一点是并非所有的强化学习系统都需要有一个模型，因此会有基于模型（Model-based）、不基于模型（Model-free）两种不同的方法，不基于模型的方法主要是通过对策略和价值函数分析进行学习。我们将模型的特点总结为以下两点：</span></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p><span style="font-size: 16px;">模型可以预测环境下一步的表现</span></p></li><li><p><span style="font-size: 16px;">表现具体可由预测的状态和奖励来反映</span></p></li></ul><section style="white-space: normal;text-indent: 2em;"><strong><span style="font-size: 16px;">学习架构：</span></strong><span style="color: rgb(77, 77, 77);font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-size: 16px;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);">我们用这样一幅图来理解一下强化学习的整体架构，大脑指代智能体agent，地球指代环境environment，从当前的状态</span><img class="rich_pages wxw-img" data-galleryid="" data-ratio="1.5277777777777777" data-s="300,640" data-type="png" data-w="36" style="text-align: center;width: 20px;height: auto !important;" src="https://mmbiz.qpic.cn/mmbiz_png/eUK9xbyE6CgBtjQtWUgPdj5mbpuQl0F4f8v4zoaxdEsl3tibQ46YpRcyHTxeD8nUcpZ5iaKDXPDUhWrPkH05AEYA/640?wx_fmt=png"  /><span style="color: rgb(77, 77, 77);font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-size: 16px;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);">出发，在做出一个行为</span><img class="rich_pages wxw-img" data-galleryid="" data-ratio="1.2307692307692308" data-s="300,640" data-type="png" data-w="39" style="text-align: center;width: 20px;height: auto !important;" src="https://mmbiz.qpic.cn/mmbiz_png/eUK9xbyE6CgBtjQtWUgPdj5mbpuQl0F46KzYU0LniaeWELytIjkYpUYzzvrlnl4d2KmfZJGicSnibgh2cN8d1NuSA/640?wx_fmt=png"  /><span style="color: rgb(77, 77, 77);font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-size: 16px;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);">之后，对环境产生了一些影响，它首先给agent反馈了一个奖励信号</span><img class="rich_pages wxw-img" data-galleryid="" data-ratio="1.2702702702702702" data-s="300,640" data-type="png" data-w="37" style="text-align: center;width: 20px;height: auto !important;" src="https://mmbiz.qpic.cn/mmbiz_png/eUK9xbyE6CgBtjQtWUgPdj5mbpuQl0F4IruHYtvujibl3NAhXkvDTgtk6PQ8EHXqxGiakECKgYXawB5S9pd0Kkug/640?wx_fmt=png"  /><span style="color: rgb(77, 77, 77);font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-size: 16px;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);">，接下来我们的agent可以从中发现一些信息，此处用</span><img class="rich_pages wxw-img" data-galleryid="" data-ratio="1.0731707317073171" data-s="300,640" data-type="png" data-w="41" style="text-align: center;width: 20px;height: auto !important;" src="https://mmbiz.qpic.cn/mmbiz_png/eUK9xbyE6CgBtjQtWUgPdj5mbpuQl0F4EYNjibpYpm3Hp0031EkAfibwVibroNiaqDxyFlGibLLM7guZRo1lFNRdMZA/640?wx_fmt=png"  /><span style="color: rgb(77, 77, 77);font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-size: 16px;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);">表示，进而进入一个新的状态，再做出新的行为，形成一个循环。强化学习的基本流程就是遵循这样一个架构。</span></section><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-ratio="1.0238693467336684" data-s="300,640" data-type="png" data-w="796" style="width: 247px;height: auto !important;" src="https://mmbiz.qpic.cn/mmbiz_png/eUK9xbyE6CgBtjQtWUgPdj5mbpuQl0F4hDuUs8OyRl5hBqVo40t7ISn5S6sTic4ibxDKlACyWPPms8z0nTwdzGww/640?wx_fmt=png"  /></p><p style="white-space: normal;"><span style="font-size: 16px;"><strong>5<strong>. 强化学习的问题</strong></strong></span></p><section style="text-indent: 2em;"><span style="font-size: 16px;">强化学习的基本问题按照两种原则进行分类。</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">基于策略和价值的分类，分为三类：</span></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p><span style="font-size: 16px;">基于价值的方法（Value Based）：没有策略但是有价值函数；</span></p></li><li><p><span style="font-size: 16px;">基于策略的方法（Policy Based）：有策略但是没有价值函数；</span></p></li><li><p><span style="font-size: 16px;">参与评价方法（Actor Critic）：既有策略也有价值函数。</span></p></li></ul><p><br  /></p><section style="text-indent: 2em;"><span style="font-size: 16px;">基于环境的分类，分为两类：</span></section><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p><span style="font-size: 16px;">无模型的方法（Model Free）：有策略和价值函数，没有模型；</span></p></li><li><p><span style="font-size: 16px;">基于模型的方法（Model Based）：有策略和价值函数，也有模型。</span></p></li></ul><p style="white-space: normal;text-align: center;"><span style="font-size: 16px;"><strong><strong><img class="rich_pages wxw-img" data-ratio="0.9019607843137255" data-type="png" data-w="969" style="width: 316px;height: auto !important;" src="https://mmbiz.qpic.cn/mmbiz_png/eUK9xbyE6CgBtjQtWUgPdj5mbpuQl0F4Qia6ZK1vZCUNkrDFUMun5mcJgsRYNcu6aBKXa5f5BOuX79elNmqhsQQ/640?wx_fmt=png"  /></strong></strong></span></p><p style="white-space: normal;"><span style="font-size: 16px;"><strong>6<strong>. 探索与利用</strong></strong></span></p><section style="text-indent: 2em;"><span style="font-size: 16px;">最后在强化学习的问题这里谈一下探索和利用的问题。强化学习理论受到行为主义心理学启发，侧重在线学习并试图在探索-利用（exploration-exploitation）间保持平衡，不要求预先给定任何数据，而是通过接收环境对动作的奖励（反馈）获得学习信息并更新模型参数。一方面，为了从环境中获取尽可能多的知识，我们要让agent进行探索，另一方面，为了获得较大的奖励，我们要让agent对已知的信息加以利用。鱼与熊掌不可兼得，我们不可能同时把探索和利用都做到最优，因此，强化学习问题中存在的一个重要挑战即是如何权衡探索-利用之间的关系。</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">强化学习是一种理解和自动化目标导向学习和决策的计算方法，它强调个体通过与环境的直接交互来学习，而不需要监督或是完整的环境模型。可以认为，强化学习是第一个有效解决从与环境交互中学习以实现长期目标的方法，而这种模式是所有形式的机器学习中最接近人类和其他动物学习的方法，也是目前最符合人工智能发展终极目标的方法。</span></section><section style="text-indent: 0em;white-space: normal;text-align: center;"><span style="font-size: 16px;"><strong>四、半监督学习</strong></span></section><section style="text-indent: 0em;white-space: normal;text-align: left;"><span style="font-size: 16px;"><strong>1.&nbsp;概念</strong><br  /></span></section><section style="white-space: normal;text-indent: 2em;"><span style="font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-size: 16px;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);color: rgb(0, 0, 0);">半监督学习是监督学习与无监督学习相结合的一种学习方法。半监督学习使用大量的未标记数据，以及同时使用标记数据，来进行模式识别工作。当使用半监督学习时，将</span><span style="font-size: 16px;"><span style="font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-variant-ligatures: no-common-ligatures;text-align: start;background-color: rgb(255, 255, 255);color: rgb(0, 0, 0);">会要求尽量少的人员来从事工作，同时，又能够带来比较高的准确性。存在的原因主要是：（1）</span>现实的数据往往缺乏标签；（2）数据标注过程的高成本；（3）很多任务很难获得如全部真实标签这样的强监督信息。</span></section><section style="text-indent: 0em;white-space: normal;"><span style="font-size: 16px;"><strong>2. 运作方式</strong><br  /></span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">半监督学习属于弱监督学习中的一个分支领域。通常来说，弱监督可以分为三类。</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">1、不完全监督（incomplete supervision），即，只有训练集的一个（通常很小的）<strong>子集是有标签的，其他数据则没有标签</strong>。这种情况发生在各类任务中。例如，在图像分类任务中，真实标签由人类标注者给出的。从互联网上获取巨量图片很容易，然而考虑到标记的人工成本，只有一个小子集的图像能够被标注或者是A卡的用户有很多会先被风控引擎等切掉一部分，导致这部分样本无法拥有好坏用户的标签。</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">2、不确切监督（inexact supervision），即只有粗粒度的标签，例如，某些图像问题只有人工打标的粗粒度的标签，这在扁平数据中也较为常见，例如社交网络用户，给这个用户打标签，用户可能是多标签的，但是在标注的过程中仅标注了一个大范围的标签，一个典型直观的例子就是给 猫打标为“猫”而没有细致到打标猫的品种，粗粒度的标签对于细粒度的任务来说帮助很有限。</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">3、不准确的监督（inaccurate supervision），模型给出的标签不总是真实的。出现这种情况的常见原因有，图片标注者的失误，或者某些图片就是难以分类，评分卡的定义都是比较明确的，而在反欺诈、异常检测的应用中，样本的标注往往是模糊的。</span></section><section style="text-indent: 2em;"><span style="color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;text-align: start;background-color: rgb(255, 255, 255);font-size: 16px;">弱监督学习是一个总括性的术语，涵盖了尝试通过较弱的监督来学习并构建预测模型的各种研究。三种弱监督的联系可见下图：</span></section><section style="text-indent: 0em;"><img class="rich_pages wxw-img" data-ratio="0.6515625" data-type="other" data-w="640" style="color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-size: medium;text-align: start;text-indent: 2em;height: auto !important;" src="https://mmbiz.qpic.cn/mmbiz/eUK9xbyE6CgBtjQtWUgPdj5mbpuQl0F4cfA3KVsoXd05BjaQpNunkiaNPs5m5z3sGuYUlSPib5ibiaEu80Pt0DjPHA/640?wx_fmt=other"  /></section><section style="text-indent: 0em;white-space: normal;"><span style="font-size: 16px;"><strong>3<strong>.&nbsp;</strong></strong></span><span style="font-size: 16px;color: rgb(0, 0, 0);"><strong>不完全监督</strong></span></section><section style="white-space: normal;text-indent: 2em;"><span style="color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;text-align: start;background-color: rgb(255, 255, 255);font-size: 16px;">不完全监督考虑那些我们只拥有少量有标注数据的情况，这些有标注数据并不足以训练出好的模型，但是我们拥有大量未标注数据可供使用。不完全监督主要包含了两个方向：</span></section><section style="margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-size: medium;text-align: start;white-space: normal;background-color: rgb(255, 255, 255);text-indent: 2em;"><span style="font-size: 16px;"><span style="font-synthesis: style;font-weight: 600;">（1）active learning 主动学习，</span>大体的思路是未标记数据通过人工专家等方法来进行查询与标注，得到了新的标签信息之后模型继续迭代，这样的过程一直重复下去，最终使得人类的经验知识越来越丰富，模型的泛化性能也越来越好，人机交互，各自获得较好的收益，当然主动学习也是一块比较大的领域，涉及到的技术细节还是非常多的，这里暂时不做深入介绍了；</span></section><section style="margin-top: 1.4em;margin-bottom: 1.4em;color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-size: medium;text-align: start;white-space: normal;background-color: rgb(255, 255, 255);text-indent: 2em;"><span style="font-size: 16px;"><span style="font-synthesis: style;font-weight: 600;">（2<span style="color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;font-weight: 600;text-align: start;text-indent: 32px;background-color: rgb(255, 255, 255);">）</span>semi-supervised learning 半监督学习，</span>按照学习方式又可以分为纯（pure）半监督学习与直推学习（transductive learning），关于二者的区别需要注意，<span style="font-synthesis: style;font-weight: 600;">直推学习（transductive learning）实际上属于另一个更大的概念，它和归纳学习（Inductive Learning）属于两种相对的学派</span>。</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">归纳学习强调的是从大量的样本中学习到潜在的规律，然后去预测未知的样本，基于“开放世界”的假设，即模型进行学习的时候不知道未来要预测的示例是什么，我们常见的逻辑回归、gbdt、nn等等都是基于这样的“开放世界”假设；</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">直推学习则是基于“封闭世界”的假设，模型在学习的过程中已经知道未来要预测的示例是什么样的。直推学习理论的鼻祖——Vapnik认为，经典的归纳学习假设期望学得一个在整个样本分布上具有低错误率的决策函数，这实际上把问题复杂化了，因为在很多情况下，人们并不关心决策函数在整个样本分布上的性能怎么样，而只是期望在给定的要预测的样本上达到最好的性能。后者比前者简单，因此，在学习过程中可以显式地考虑测试样本从而更容易地达到目的。</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">从基于两种学习方式的算法的使用方法层面上来说：<strong>直推式半监督中只包含有标签样本集和测试样本集，且测试样本也是无标签样本</strong>。<strong>直推式半监督算法先将测试样本视为无标签样本，然后利用有标签样本和无标签样本训练模型，并在训练过程中预测无标签样本</strong>。因此，直推式半监督算法只能处理当前的无标签样本（测试样本）（wordvec实际上就是一个典型的例子），不能直接进行样本外的扩展。对于新的测试样本，直推式半监督算法需要重新训练模型才能预测其标签。</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">归纳式半监督算法除了使用有标签样本集和无标签样本集外，还使用独立的测试样本集。归纳式半监督算法能够处理整个样本空间中的样本。归纳式半监督算法在有标签样本和无标签样本上训练学习模型。该模型不仅可以预测训练无标签样本的标签，还能直接预测新测试样本的标签。</span></section><p style="white-space: normal;"><span style="font-size: 16px;"><strong>4<strong>. 半监督学习</strong></strong></span></p><section style="text-indent: 2em;"><span style="font-size: 16px;">self-training，即自我训练，也称之为伪标签技术，初代半监督思想的经典代表，其基本思路就是，在已标记的数据上训练，然后对未标注数据进行预测，取预测置信度最高的样本直接对其进行标签定义，然后将这类样本纳入当前训练样本中继续训练，直到模型的预测结果不再发生变化；</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">如果是分类问题：选择预测概率最有把握的样本的标签作为真实的标签（例如概率为0.99或者概率未0.01的预测标签），将预测然后将得到的有标注的数据加入原始数据继续进行训练，再预测，一直到达停止条件（例如大部分甚至全部unlabeled的样本都被打上了标签），此时，我们就把未标注的样本通过这种方式标注出来了；</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">如果是回归问题，则进行第一轮预测，将预测结果作为新的标签，然后将unlabeled和labeled的数据合并进行训练，再进行第二次预测，计算两次预测的结果中，unlabeled数据的误差情况，取误差最小的部分样本直接进行标签的定义，最后按照上述的思路反复迭代一直到误差收敛为止，此时，我们就把未标注的样本通过这种方式标注出来了；</span></section><section style="text-indent: 2em;"><span style="font-size: 16px;">自我训练<span style="color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;text-align: start;background-color: rgb(255, 255, 255);">实际上是一种数据增广的方式，基学习器可以使用的配置不同，但是只有当初始和后续的类别正确的标记了绝大多数样本时，才能通过迭代改进分类的精度，否则，你使用性能很差的分类模型或者回归模型只会预测出大量错误的标签，从而使得模型在迭代的过程中“错上加错”，然而，即使是高精度的模型，也会不可避免的添加错误的标记噪音，在实际应用中，使用更准确地信任度量（例如99%或者0.01%的阈值）和预定义地置信度阈值来限制错误标记地样本的数量,对于回归问题，我们可以使用多次交叉验证之后取回归预测值的标准差作为衡量，标准差越小则置信度越高。</span></span></section><section style="text-indent: 2em;"><span style="color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;text-align: start;background-color: rgb(255, 255, 255);font-size: 16px;">伪标签技术大体可以分为硬标签和软标签，硬标签是直接人工确定某个阈值，然后进行无标签数据的标签判定，而软标签技术从另一个角度提出了一种self traning的思路，主要针对于分类问题，其思路也不复杂，就是根据概率对样本的权重进行定义，例如在二分类问题中，我们对样本A预测的概率为0.4与0.6，则我们将A当作两个样本，标签为0的样本其权重为0.4，标签为1的样本其权重为0.6，而后加入原始的数据进行训练和迭代直到收敛或达到预先定义的停止条件为止。</span></section><section style="text-indent: 2em;"><span style="color: rgb(18, 18, 18);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;text-align: start;background-color: rgb(255, 255, 255);font-size: 16px;">关于半监督学习的算法请看该文章：https://zhuanlan.zhihu.com/p/349107869。此外还存在深度半监督学习。</span></section><p style="white-space: normal;"><span style="font-size: 16px;"><strong>5<strong>.&nbsp;应用中存在的问题</strong></strong></span></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><section style="white-space: normal;text-indent: 2em;"><span style="font-size: 16px;">无标签样本的有效利用问题。上述使用的各类半监督学习算法在训练阶段都没有太多考虑无标签样本的质量问题，如果无标签样本的质量比较差甚至是完全不同分布的数据，那么很容易反而降低模型的泛化性能。</span></section></li><li><section style="text-indent: 2em;"><span style="font-size: 16px;">大量无标签样本的高效使用问题。半监督算法的计算复杂度、提升性能的效果以及可扩展性、易用性等都是在实际的工程中要考虑的问题，例如上面所说的TSVM，SVM本身的计算效率就不高，基于半监督不断进行迭代与收敛会使得整个算法的运行时间特别长，而且，就目前风控以lr和gbdt为主的情况下，TSVM难以扩展到这两个算法上面来。</span></section><section style="text-indent: 2em;"><br  /></section></li><li><p><br  /></p><section style="text-indent: 2em;"><span style="font-size: 16px;">特征选择中的有效性问题。可以看到，很多半监督的算法都有无监督的影子，即在没有标签的情况下使用各种奇怪的套路，比如标签传播算法，所以和无监督一样，这类半监督算法对于特征的选择非常的敏感，如果你的特征有很多的辣鸡特征，那么可能效果就会大打折扣了。</span></section><p><br  /></p></li></ul><hr style="border-style: solid;border-width: 1px 0 0;border-color: rgba(0,0,0,0.1);-webkit-transform-origin: 0 0;-webkit-transform: scale(1, 0.5);transform-origin: 0 0;transform: scale(1, 0.5);"  /><p><span style="font-size: 16px;"><br  /></span></p><p><span style="font-size: 16px;">参考资料：</span></p><p><span style="font-size: 16px;">监督学习与无监督学习：</span></p><p><span style="font-size: 16px;">https://blog.csdn.net/weixin_46211269/article/details/125093635</span></p><p><span style="font-size: 16px;">强化学习：</span></p><p><span style="font-size: 16px;">https://blog.csdn.net/weixin_45560318/article/details/112981006</span></p><p><span style="font-size: 16px;">弱监督学习：</span></p><p><span style="font-size: 16px;">https://zhuanlan.zhihu.com/p/349107869</span></p><section class="mp_profile_iframe_wrp"><mp-common-profile class="custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-weuitheme="light" data-id="MzA3NjIzNjMwOA==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/hXibVSNciaXhzia07WkYkDfaRxHUiaDaNc5x3xTNO1RlNBRhPnxpEzoemhsn7ofat4pVwVgOktaveEtu6IKzzLONQQ/0?wx_fmt=png" data-nickname="数据治理体系" data-alias="DGsystem" data-signature="持续完善数据治理实战体系，数据仓库、标签、指标体系，实现业务数字化，数字资产化，资产业务化，资产资本化；回归业务场景的数字化案例才最具参考价值，最容易理解和借鉴的。关注我，和您一起终身学习。" data-from="0" data-weui-theme="light"></mp-common-profile><br  /></section><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p></content>
</div>
</body>
</html>